- ingressFrom:
    identities:
    # A GCP Service Account for the new workspace is created in the Databricks regional control plane project. 
    # We use the login user’s (workspace creator) OAuth token to grant the Consumer SA with sufficient permissions 
    # to setup and operate Databricks workspaces in the customer’s consumer (GCP) project. 
    # Consumer SA follow’s db-WORKSPACEID@databricks-project.iam.gserviceaccount.com naming convention. 
    # Workspace ID is generated as part of the workspace creation process.
    # E.g. db-nnnnnnnnnnnnn@prod-gcp-[databricks-supported-gcp-region].iam.gserviceaccount.com
    - serviceAccount:db-3812577995730654@prod-gcp-us-central1.iam.gserviceaccount.com
    - serviceAccount:log-delivery@databricks-prod-master.iam.gserviceaccount.com # please refer to this doc for more info https://docs.gcp.databricks.com/administration-guide/account-settings-gcp/log-delivery.html
    sources:
    # request originating from databricks control plane shard project
    # after the workspace is created we only need ingress from regional control plane
    # so if the workspace is in us-east4 then we need databricks us-east4 control plane project number
    - resource: projects/121886670913 #us-east4 control plane project
    - resource: projects/85638097580 #databricks control plane project responsible to deliver audit logs into your GCS bucket
  ingressTo:
    operations:
    - methodSelectors:
      - method: 'NetworksService.Get'
      - method: 'ProjectsService.Get'
      - method: 'SubnetworksService.Get'
      - method: 'ZonesService.List'
      - method: 'RegionsService.Get'
      serviceName: compute.googleapis.com
    - methodSelectors:
      - method: 'google.storage.objects.create'
      - method: 'google.storage.buckets.testIamPermissions'
      - method: 'google.storage.objects.get'
      - method: 'google.storage.objects.list'
      # required by databricks dbsql
      - method: 'google.storage.buckets.get'
      # required by databricks mlflow autom_ml feature
      - method: 'google.storage.objects.delete'
      serviceName: storage.googleapis.com
    - methodSelectors:
      # container api does not support method level filtering
      - method: '*'
      serviceName: container.googleapis.com
    - methodSelectors:
      - method: '*'
      serviceName: logging.googleapis.com
    - methodSelectors:
    # cloudresourcemanager api does not support method level filtering
      - method: '*'
      serviceName: cloudresourcemanager.googleapis.com
    - methodSelectors:
    # iam api does not support method level filtering
      - method: '*'
      serviceName: iam.googleapis.com
    resources:
    # projects on which you would like to enforce this ingress policy
    # multiple entries could be added with additional - projects/project_number entries
    # if you are using shared-vpc then we'll need project_number for host-project (shared-vpc) as well as the service project (databricks workspace)
    # host project provides the vpc and servcie project is where Databricks creates GKE cluster and Databricks related GCS storage accounts
    - projects/872269723794
    #- projects/1063849655298