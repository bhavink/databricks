curl -n \
-X POST -H 'Content-Type: application/json' \
-d '{
"cluster_name": "bk-etl-job-server",
"spark_version": "4.1.x-scala2.11",
      "spark_conf": {
          "spark.databricks.io.cache.enabled": "true",
          "spark.rdd.compress": "true",
          "spark.sql.crossJoin.enabled": "true"
      },
      "node_type_id": "Standard_L4s",
      "driver_node_type_id": "Standard_L4s",
      "autoscale": {
        "min_workers": 2,
        "max_workers": 10
        },
      "cluster_log_conf": {
          "dbfs": {
              "destination": "dbfs:/mnt/bhavin/adls/cluster-logs"
          }
      },
      "custom_tags": {
            "Team": "ETLProd",
            "Project": "Overnight Data Feed Extraction Prod",
            "CostCenter": "Prod101",
            "Env": "Prod"
        },      
      "autotermination_minutes": 120,
      "enable_elastic_disk": true
}' \
https://eastus2.azuredatabricks.net/api/2.0/dbfs/put -H "Authorization: Bearer your-token"