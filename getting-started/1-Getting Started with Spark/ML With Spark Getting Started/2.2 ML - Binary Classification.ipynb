{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Databricks notebook source\n",
    "MAGIC %md\n",
    "MAGIC # Binary Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines.\n",
    "MAGIC You can read more about the Pipelines API in the [programming guide](https://spark.apache.org/docs/latest/ml-guide.html).\n",
    "MAGIC \n",
    "MAGIC **Binary Classification** is the task of predicting a binary label.\n",
    "MAGIC E.g., is an email spam or not spam? Should I show this ad to this user or not? Will it rain tomorrow or not?\n",
    "MAGIC This section demonstrates algorithms for making these types of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Dataset Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC The Adult dataset we are going to use is publicly available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "MAGIC This data derives from census data, and consists of information about 48842 individuals and their annual income.\n",
    "MAGIC We will use this information to predict if an individual earns **<=50K or >50k** a year.\n",
    "MAGIC The dataset is rather clean, and consists of both numeric and categorical variables.\n",
    "MAGIC \n",
    "MAGIC Attribute Information:\n",
    "MAGIC \n",
    "MAGIC - age: continuous\n",
    "MAGIC - workclass: Private,Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n",
    "MAGIC - fnlwgt: continuous\n",
    "MAGIC - education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n",
    "MAGIC - education-num: continuous\n",
    "MAGIC - marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n",
    "MAGIC - occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n",
    "MAGIC - relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n",
    "MAGIC - race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n",
    "MAGIC - sex: Female, Male\n",
    "MAGIC - capital-gain: continuous\n",
    "MAGIC - capital-loss: continuous\n",
    "MAGIC - hours-per-week: continuous\n",
    "MAGIC - native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n",
    "MAGIC \n",
    "MAGIC Target/Label: - <=50K, >50K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC In this example, we will read in the Adult dataset from databricks-datasets.\n",
    "MAGIC We'll read in the data in SQL using the CSV data source for Spark and rename the columns appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %fs ls databricks-datasets/adult/adult.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %fs head databricks-datasets/adult/adult.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %sql DROP TABLE IF EXISTS adult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC CREATE TABLE adult (\n",
    "MAGIC   age DOUBLE,\n",
    "MAGIC   workclass STRING,\n",
    "MAGIC   fnlwgt DOUBLE,\n",
    "MAGIC   education STRING,\n",
    "MAGIC   education_num DOUBLE,\n",
    "MAGIC   marital_status STRING,\n",
    "MAGIC   occupation STRING,\n",
    "MAGIC   relationship STRING,\n",
    "MAGIC   race STRING,\n",
    "MAGIC   sex STRING,\n",
    "MAGIC   capital_gain DOUBLE,\n",
    "MAGIC   capital_loss DOUBLE,\n",
    "MAGIC   hours_per_week DOUBLE,\n",
    "MAGIC   native_country STRING,\n",
    "MAGIC   income STRING)\n",
    "MAGIC USING CSV\n",
    "MAGIC OPTIONS (path \"/databricks-datasets/adult/adult.data\", header \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.table(\"adult\")\n",
    "cols = dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Preprocess Data\n",
    "MAGIC \n",
    "MAGIC Since we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables.\n",
    "MAGIC There are 2 ways we can do this.\n",
    "MAGIC \n",
    "MAGIC * Category Indexing\n",
    "MAGIC \n",
    "MAGIC   This is basically assigning a numeric value to each category from {0, 1, 2, ...numCategories-1}.\n",
    "MAGIC   This introduces an implicit ordering among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\n",
    "MAGIC \n",
    "MAGIC * One-Hot Encoding\n",
    "MAGIC \n",
    "MAGIC   This converts categories into binary vectors with at most one nonzero value (eg: (Blue: [1, 0]), (Green: [0, 1]), (Red: [0, 0]))\n",
    "MAGIC \n",
    "MAGIC In this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc).\n",
    "MAGIC For simplicity's sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors.\n",
    "MAGIC It is possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\n",
    "MAGIC \n",
    "MAGIC Here, we will use a combination of [StringIndexer] and [OneHotEncoderEstimator] to convert the categorical variables.\n",
    "MAGIC The `OneHotEncoderEstimator` will return a [SparseVector].\n",
    "MAGIC \n",
    "MAGIC Since we will have more than 1 stage of feature transformations, we use a [Pipeline] to tie the stages together.\n",
    "MAGIC This simplifies our code.\n",
    "MAGIC \n",
    "MAGIC [StringIndexer]: http://spark.apache.org/docs/latest/ml-features.html#stringindexer\n",
    "MAGIC [OneHotEncoderEstimator]: https://spark.apache.org/docs/latest/ml-features.html#onehotencoderestimator\n",
    "MAGIC [SparseVector]: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.linalg.SparseVector\n",
    "MAGIC [Pipeline]: http://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalColumns:\n",
    "    # Category Indexing with StringIndexer\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "    # encoder = OneHotEncoderEstimator(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"classVec\")\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    # Add stages.  These are not run here, but will run all at once later on.\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC The above code basically indexes each categorical column using the `StringIndexer`,\n",
    "MAGIC and then converts the indexed categories into one-hot encoded variables.\n",
    "MAGIC The resulting output has the binary vectors appended to the end of each row.\n",
    "MAGIC \n",
    "MAGIC We use the `StringIndexer` again to encode our labels to label indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label into label indices using the StringIndexer\n",
    "label_stringIdx = StringIndexer(inputCol=\"income\", outputCol=\"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Use a `VectorAssembler` to combine all the feature columns into a single vector column.\n",
    "MAGIC This includes both the numeric columns and the one-hot encoded binary vector columns in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all features into a vector using VectorAssembler\n",
    "numericCols = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Run the stages as a Pipeline. This puts the data through all of the feature transformations we described in a single call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partialPipeline = Pipeline().setStages(stages)\n",
    "pipelineModel = partialPipeline.fit(dataset)\n",
    "preppedDataDF = pipelineModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to prepped data\n",
    "lrModel = LogisticRegression().fit(preppedDataDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC for training data\n",
    "display(lrModel, preppedDataDF, \"ROC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(lrModel, preppedDataDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "selectedcols = [\"label\", \"features\"] + cols\n",
    "dataset = preppedDataDF.select(selectedcols)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Randomly split data into training and test sets. set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed=100)\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Fit and Evaluate Models\n",
    "MAGIC \n",
    "MAGIC We are now ready to try out some of the Binary Classification algorithms available in the Pipelines API.\n",
    "MAGIC \n",
    "MAGIC Out of these algorithms, the below are also capable of supporting multiclass classification with the Python API:\n",
    "MAGIC - Decision Tree Classifier\n",
    "MAGIC - Random Forest Classifier\n",
    "MAGIC \n",
    "MAGIC These are the general steps we will take to build our models:\n",
    "MAGIC - Create initial model using the training set\n",
    "MAGIC - Tune parameters with a `ParamGrid` and 5-fold Cross Validation\n",
    "MAGIC - Evaluate the best model obtained from the Cross Validation using the test set\n",
    "MAGIC \n",
    "MAGIC We use the `BinaryClassificationEvaluator` to evaluate our models, which uses [areaUnderROC] as the default metric.\n",
    "MAGIC \n",
    "MAGIC [areaUnderROC]: https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC \n",
    "MAGIC ## Logistic Regression\n",
    "MAGIC \n",
    "MAGIC You can read more about [Logistic Regression] from the [classification and regression] section of MLlib Programming Guide.\n",
    "MAGIC In the Pipelines API, we are now able to perform Elastic-Net Regularization with Logistic Regression, as well as other linear methods.\n",
    "MAGIC \n",
    "MAGIC [classification and regression]: https://spark.apache.org/docs/latest/ml-classification-regression.html\n",
    "MAGIC [Logistic Regression]: https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Training Data\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the transform() method.\n",
    "# LogisticRegression.transform() will only use the 'features' column.\n",
    "predictions = lrModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "# You can select any columns in the above schema to view as well. For example's sake we will choose age & occupation\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC We can use ``BinaryClassificationEvaluator`` to evaluate our model. We can set the required column names in `rawPredictionCol` and `labelCol` Param and the metric in `metricName` Param."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Note that the default metric for the ``BinaryClassificationEvaluator`` is ``areaUnderROC``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.getMetricName()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC The evaluator currently accepts 2 kinds of metrics - areaUnderROC and areaUnderPR.\n",
    "MAGIC We can set it to areaUnderPR by using evaluator.setMetricName(\"areaUnderPR\").\n",
    "MAGIC \n",
    "MAGIC Now we will try tuning the model with the ``ParamGridBuilder`` and the ``CrossValidator``.\n",
    "MAGIC \n",
    "MAGIC If you are unsure what params are available for tuning, you can use ``explainParams()`` to print a list of all params and their definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC As we indicate 3 values for regParam, 3 values for maxIter, and 2 values for elasticNetParam,\n",
    "MAGIC this grid will have 3 x 3 x 3 = 27 parameter settings for CrossValidator to choose from.\n",
    "MAGIC We will create a 5-fold cross validator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set to measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC We can also access the model's feature weights and intercepts easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Intercept: ', cvModel.bestModel.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cvModel.bestModel.coefficients\n",
    "weights = [(float(w),) for w in weights]  # convert numpy type to float, and to tuple\n",
    "weightsDF = sqlContext.createDataFrame(weights, [\"Feature Weight\"])\n",
    "display(weightsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View best model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Decision Trees\n",
    "MAGIC \n",
    "MAGIC You can read more about [Decision Trees](http://spark.apache.org/docs/latest/mllib-decision-tree.html) in the Spark MLLib Programming Guide.\n",
    "MAGIC The Decision Trees algorithm is popular because it handles categorical\n",
    "MAGIC data and works out of the box with multiclass classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial Decision Tree Model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Training Data\n",
    "dtModel = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC We can extract the number of nodes in our decision tree as well as the\n",
    "MAGIC tree depth of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numNodes = \", dtModel.numNodes)\n",
    "print(\"depth = \", dtModel.depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dtModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "predictions = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC We will evaluate our Decision Tree model with\n",
    "MAGIC `BinaryClassificationEvaluator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Entropy and the Gini coefficient are the supported measures of impurity for Decision Trees. This is ``Gini`` by default. Changing this value is simple, ``model.setImpurity(\"Entropy\")``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.getImpurity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Now we will try tuning the model with the ``ParamGridBuilder`` and the ``CrossValidator``.\n",
    "MAGIC \n",
    "MAGIC As we indicate 3 values for maxDepth and 3 values for maxBin, this grid will have 3 x 3 = 9 parameter settings for ``CrossValidator`` to choose from. We will create a 5-fold CrossValidator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(dt.maxDepth, [1, 2, 6, 10])\n",
    "             .addGrid(dt.maxBins, [20, 40, 80])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross validations\n",
    "cvModel = cv.fit(trainingData)\n",
    "# Takes ~5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numNodes = \", cvModel.bestModel.numNodes)\n",
    "print(\"depth = \", cvModel.bestModel.depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set to measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Best model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Random Forest\n",
    "MAGIC \n",
    "MAGIC Random Forests uses an ensemble of trees to improve model accuracy.\n",
    "MAGIC You can read more about [Random Forest] from the [classification and regression] section of MLlib Programming Guide.\n",
    "MAGIC \n",
    "MAGIC [classification and regression]: https://spark.apache.org/docs/latest/ml-classification-regression.html\n",
    "MAGIC [Random Forest]: https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an initial RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test data using the Transformer.transform() method.\n",
    "predictions = rfModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC We will evaluate our Random Forest model with `BinaryClassificationEvaluator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC Now we will try tuning the model with the ``ParamGridBuilder`` and the ``CrossValidator``.\n",
    "MAGIC \n",
    "MAGIC As we indicate 3 values for maxDepth, 2 values for maxBin, and 2 values for numTrees,\n",
    "MAGIC this grid will have 3 x 2 x 2 = 12 parameter settings for ``CrossValidator`` to choose from.\n",
    "MAGIC We will create a 5-fold ``CrossValidator``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParamGrid for Cross Validation\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "             .addGrid(rf.maxBins, [20, 60])\n",
    "             .addGrid(rf.numTrees, [5, 20])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\n",
    "cvModel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set here so we can measure the accuracy of our model on new data\n",
    "predictions = cvModel.transform(testData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Best model's predictions and probabilities of each prediction class\n",
    "selected = predictions.select(\"label\", \"prediction\", \"probability\", \"age\", \"occupation\")\n",
    "display(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC ## Make Predictions\n",
    "MAGIC As Random Forest gives us the best areaUnderROC value, we will use the bestModel obtained from Random Forest for deployment,\n",
    "MAGIC and use it to generate predictions on new data.\n",
    "MAGIC In this example, we will simulate this by generating predictions on the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModel = cvModel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for entire dataset\n",
    "finalPredictions = bestModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model\n",
    "evaluator.evaluate(finalPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC In this example, we will also look into predictions grouped by age and occupation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPredictions.createOrReplaceTempView(\"finalPredictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %md\n",
    "MAGIC In an operational environment, analysts may use a similar machine learning pipeline to obtain predictions on new data, organize it into a table and use it for analysis or lead targeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC SELECT occupation, prediction, count(*) AS count\n",
    "MAGIC FROM finalPredictions\n",
    "MAGIC GROUP BY occupation, prediction\n",
    "MAGIC ORDER BY occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMAND ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC %sql\n",
    "MAGIC SELECT age, prediction, count(*) AS count\n",
    "MAGIC FROM finalPredictions\n",
    "MAGIC GROUP BY age, prediction\n",
    "MAGIC ORDER BY age"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
